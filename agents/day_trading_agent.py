# Code Generated by Sidekick is for learning and experimentation purposes only.
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import logging
from dataclasses import dataclass
from enum import Enum

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'data'))
from data.signal_generator import ComprehensiveSignalGenerator
from data.indicator_analysis import get_params_by_timeframe

class SignalType(Enum):
    BASIC_INDICATORS = "basic_indicators"
    FIBONACCI = "fibonacci"
    ELLIOTT_WAVE = "elliott_wave"

class TradingAction(Enum):
    STRONG_BUY = "STRONG_BUY"
    BUY = "BUY"
    HOLD = "HOLD"
    SELL = "SELL"
    STRONG_SELL = "STRONG_SELL"

@dataclass
class TradingRecommendation:
    action: TradingAction
    confidence: float
    entry_price: Optional[float]
    stop_loss: Optional[float]
    take_profit: Optional[float]
    risk_reward_ratio: Optional[float]
    reasoning: List[str]
    timeframe_analysis: Dict[str, float]

class AdvancedScoringEngine:
    """Advanced scoring logic for different signal types"""
    
    def __init__(self):
        # Weights for different signal categories
        self.signal_weights = {
            SignalType.BASIC_INDICATORS: {
                'trend_following': 0.35,
                'momentum': 0.25,
                'volatility': 0.15,
                'volume': 0.25
            },
            SignalType.FIBONACCI: {
                'retracement_proximity': 0.40,
                'trend_alignment': 0.35,
                'level_significance': 0.25
            },
            SignalType.ELLIOTT_WAVE: {
                'pattern_confidence': 0.45,
                'wave_position': 0.30,
                'trend_strength': 0.25
            }
        }
        
        # Timeframe importance weights
        self.timeframe_weights = {
            '1m': 0.10,
            '5m': 0.15,
            '15m': 0.20,
            '1h': 0.25,
            'day': 0.30
        }

    def score_basic_indicators(self, signals: Dict) -> Dict[str, float]:
        """Score basic technical indicators with advanced logic"""
        scores = {
            'trend_score': 0,
            'momentum_score': 0,
            'volatility_score': 0,
            'volume_score': 0,
            'overall_score': 0
        }
        
        entry_signals = signals.get('entry_signals', [])
        exit_signals = signals.get('exit_signals', [])
        bullish_score = signals.get('scores', {}).get('bullish', 0)
        bearish_score = signals.get('scores', {}).get('bearish', 0)
        
        # Trend Following Indicators (MACD, SMA, Supertrend)
        trend_signals = [s for s in entry_signals if any(keyword in s.lower() 
                        for keyword in ['macd', 'sma', 'supertrend', 'linreg'])]
        trend_exits = [s for s in exit_signals if any(keyword in s.lower() 
                      for keyword in ['macd', 'sma', 'supertrend', 'linreg'])]
        
        scores['trend_score'] = min(100, (len(trend_signals) * 20) - (len(trend_exits) * 15))
        
        # Momentum Indicators (RSI, Stochastic, CCI, ROC)
        momentum_signals = [s for s in entry_signals if any(keyword in s.lower() 
                           for keyword in ['rsi', 'stochastic', 'cci', 'roc'])]
        momentum_exits = [s for s in exit_signals if any(keyword in s.lower() 
                         for keyword in ['rsi', 'stochastic', 'cci', 'roc'])]
        
        scores['momentum_score'] = min(100, (len(momentum_signals) * 25) - (len(momentum_exits) * 20))
        
        # Volatility Indicators (ATR, Historical Volatility, Donchian)
        volatility_signals = [s for s in entry_signals if any(keyword in s.lower() 
                             for keyword in ['atr', 'volatility', 'donchian'])]
        
        scores['volatility_score'] = min(100, len(volatility_signals) * 30)
        
        # Volume Indicators (OBV)
        volume_signals = [s for s in entry_signals if 'obv' in s.lower()]
        volume_exits = [s for s in exit_signals if 'obv' in s.lower()]
        
        scores['volume_score'] = min(100, (len(volume_signals) * 35) - (len(volume_exits) * 30))
        
        # Calculate weighted overall score
        weights = self.signal_weights[SignalType.BASIC_INDICATORS]
        scores['overall_score'] = (
            scores['trend_score'] * weights['trend_following'] +
            scores['momentum_score'] * weights['momentum'] +
            scores['volatility_score'] * weights['volatility'] +
            scores['volume_score'] * weights['volume']
        )
        
        return scores

    def score_fibonacci_signals(self, fibonacci_data: Dict) -> Dict[str, float]:
        """Advanced Fibonacci retracement/extension scoring"""
        scores = {
            'retracement_score': 0,
            'trend_alignment_score': 0,
            'level_significance_score': 0,
            'overall_score': 0
        }
        
        if not fibonacci_data:
            return scores
        
        current_price = fibonacci_data.get('current_price', 0)
        trend_direction = fibonacci_data.get('trend_direction', '')
        nearest_support = fibonacci_data.get('nearest_support', {})
        nearest_resistance = fibonacci_data.get('nearest_resistance', {})
        key_levels = fibonacci_data.get('key_levels', {})
        
        # Retracement Proximity Score
        proximity_scores = []
        for level_name, level_price in key_levels.items():
            if level_price and current_price:
                distance_pct = abs(level_price - current_price) / current_price * 100
                if distance_pct < 0.5:  # Very close
                    proximity_scores.append(100)
                elif distance_pct < 1.0:  # Close
                    proximity_scores.append(80)
                elif distance_pct < 2.0:  # Moderate
                    proximity_scores.append(60)
                else:
                    proximity_scores.append(20)
        
        scores['retracement_score'] = max(proximity_scores) if proximity_scores else 0
        
        # Trend Alignment Score
        if trend_direction == 'uptrend':
            if nearest_support and current_price:
                support_distance = abs(current_price - nearest_support.get('price', 0)) / current_price * 100
                scores['trend_alignment_score'] = max(0, 100 - (support_distance * 20))
        elif trend_direction == 'downtrend':
            if nearest_resistance and current_price:
                resistance_distance = abs(current_price - nearest_resistance.get('price', 0)) / current_price * 100
                scores['trend_alignment_score'] = max(0, 100 - (resistance_distance * 20))
        
        # Level Significance Score (based on key Fibonacci ratios)
        significant_levels = ['38.2%', '50%', '61.8%', '78.6%']
        if nearest_support and nearest_support.get('level') in significant_levels:
            scores['level_significance_score'] += 50
        if nearest_resistance and nearest_resistance.get('level') in significant_levels:
            scores['level_significance_score'] += 50
        
        # Calculate weighted overall score
        weights = self.signal_weights[SignalType.FIBONACCI]
        scores['overall_score'] = (
            scores['retracement_score'] * weights['retracement_proximity'] +
            scores['trend_alignment_score'] * weights['trend_alignment'] +
            scores['level_significance_score'] * weights['level_significance']
        )
        
        return scores

    def score_elliott_wave_signals(self, elliott_wave_data: Dict) -> Dict[str, float]:
        """Advanced Elliott Wave pattern scoring"""
        scores = {
            'pattern_confidence_score': 0,
            'wave_position_score': 0,
            'trend_strength_score': 0,
            'overall_score': 0
        }
        
        if not elliott_wave_data:
            return scores
        
        pattern = elliott_wave_data.get('pattern', '')
        trend = elliott_wave_data.get('trend', '')
        confidence = elliott_wave_data.get('confidence', 0)
        impulse_score = elliott_wave_data.get('impulse_score', 0)
        corrective_score = elliott_wave_data.get('corrective_score', 0)
        
        # Pattern Confidence Score
        scores['pattern_confidence_score'] = confidence
        
        # Wave Position Score
        if pattern == 'impulse':
            if trend == 'bullish':
                scores['wave_position_score'] = 85  # Strong bullish impulse
            else:
                scores['wave_position_score'] = 15  # Bearish impulse (exit signal)
        elif pattern == 'corrective':
            scores['wave_position_score'] = 50  # Neutral, waiting for completion
        
        # Trend Strength Score
        pattern_strength = max(impulse_score, corrective_score)
        scores['trend_strength_score'] = pattern_strength
        
        # Calculate weighted overall score
        weights = self.signal_weights[SignalType.ELLIOTT_WAVE]
        scores['overall_score'] = (
            scores['pattern_confidence_score'] * weights['pattern_confidence'] +
            scores['wave_position_score'] * weights['wave_position'] +
            scores['trend_strength_score'] * weights['trend_strength']
        )
        
        return scores

class RiskManagementEngine:
    """Advanced risk management and position sizing"""
    
    def __init__(self):
        self.max_risk_per_trade = 0.02  # 2% max risk per trade
        self.max_portfolio_risk = 0.06  # 6% max total portfolio risk
        
    def calculate_position_size(self, account_balance: float, entry_price: float, 
                              stop_loss: float, risk_percentage: float = 0.02) -> Dict:
        """Calculate optimal position size based on risk management"""
        if not entry_price or not stop_loss or entry_price == stop_loss:
            return {'position_size': 0, 'risk_amount': 0, 'error': 'Invalid price levels'}
        
        risk_amount = account_balance * risk_percentage
        price_risk = abs(entry_price - stop_loss)
        position_size = risk_amount / price_risk
        
        return {
            'position_size': position_size,
            'risk_amount': risk_amount,
            'price_risk': price_risk,
            'risk_percentage': risk_percentage
        }
    
    def calculate_stop_loss_take_profit(self, entry_price: float, signals: Dict, 
                                      atr_value: float = None) -> Tuple[float, float]:
        """Calculate dynamic stop loss and take profit levels"""
        if not entry_price:
            return None, None
        
        # Use ATR for dynamic levels if available
        if atr_value:
            stop_loss_distance = atr_value * 2
            take_profit_distance = atr_value * 3
        else:
            # Fallback to percentage-based levels
            stop_loss_distance = entry_price * 0.015  # 1.5%
            take_profit_distance = entry_price * 0.030  # 3%
        
        overall_bias = signals.get('overall_bias', 'neutral')
        
        if overall_bias == 'bullish':
            stop_loss = entry_price - stop_loss_distance
            take_profit = entry_price + take_profit_distance
        elif overall_bias == 'bearish':
            stop_loss = entry_price + stop_loss_distance
            take_profit = entry_price - take_profit_distance
        else:
            return None, None
        
        return stop_loss, take_profit

class DayTradingAgent:
    """Comprehensive Day Trading Agent with Advanced Decision Making"""
    
    def __init__(self, account_balance: float = 10000):
        self.signal_generator = ComprehensiveSignalGenerator()
        self.scoring_engine = AdvancedScoringEngine()
        self.risk_engine = RiskManagementEngine()
        self.account_balance = account_balance
        
        # Configure logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # Decision thresholds
        self.decision_thresholds = {
            'strong_buy': 80,
            'buy': 65,
            'hold': 35,
            'sell': 20,
            'strong_sell': 0
        }

    def analyze_symbol(self, symbol: str, timeframe: str, indicators_df: pd.DataFrame) -> TradingRecommendation:
        """
        Main analysis function that generates comprehensive trading recommendations
        
        Args:
            symbol: Trading symbol (e.g., 'AAPL', 'BTCUSD')
            timeframe: Time interval ('1m', '5m', '15m', '1h', 'day')
            indicators_df: DataFrame with calculated indicators
            
        Returns:
            TradingRecommendation object with detailed analysis
        """
        try:
            # Get timeframe-specific parameters
            params = get_params_by_timeframe(timeframe)
            
            # Generate signals from your existing signal generator
            signals = self.signal_generator.last_signal(indicators_df, params)
            
            if not signals:
                return self._create_neutral_recommendation("No signals generated")
            
            # Extract advanced analysis data
            last_row = indicators_df.iloc[-1]
            fibonacci_data = last_row.get('Fibonacci', {})
            elliott_wave_data = last_row.get('Elliott_Wave', {})
            current_price = last_row.get('close', 0)
            atr_value = last_row.get('ATR_14', None)
            
            # Score different signal types
            basic_scores = self.scoring_engine.score_basic_indicators(signals)
            fibonacci_scores = self.scoring_engine.score_fibonacci_signals(fibonacci_data)
            elliott_wave_scores = self.scoring_engine.score_elliott_wave_signals(elliott_wave_data)
            
            # Calculate composite score
            composite_score = self._calculate_composite_score(
                basic_scores, fibonacci_scores, elliott_wave_scores, timeframe
            )
            
            # Generate trading decision
            action = self._determine_trading_action(composite_score)
            
            # Calculate risk management parameters
            stop_loss, take_profit = self.risk_engine.calculate_stop_loss_take_profit(
                current_price, signals, atr_value
            )
            
            # Calculate position sizing
            position_info = self.risk_engine.calculate_position_size(
                self.account_balance, current_price, stop_loss
            )
            
            # Generate reasoning
            reasoning = self._generate_reasoning(
                signals, basic_scores, fibonacci_scores, elliott_wave_scores, 
                composite_score, timeframe
            )
            
            # Calculate risk-reward ratio
            risk_reward_ratio = None
            if stop_loss and take_profit and current_price:
                risk = abs(current_price - stop_loss)
                reward = abs(take_profit - current_price)
                risk_reward_ratio = reward / risk if risk > 0 else None
            
            # Create timeframe analysis
            timeframe_analysis = self._create_timeframe_analysis(
                basic_scores, fibonacci_scores, elliott_wave_scores
            )
            
            return TradingRecommendation(
                action=action,
                confidence=composite_score,
                entry_price=current_price,
                stop_loss=stop_loss,
                take_profit=take_profit,
                risk_reward_ratio=risk_reward_ratio,
                reasoning=reasoning,
                timeframe_analysis=timeframe_analysis
            )
            
        except Exception as e:
            self.logger.error(f"Error analyzing {symbol}: {str(e)}")
            return self._create_neutral_recommendation(f"Analysis error: {str(e)}")

    def _calculate_composite_score(self, basic_scores: Dict, fibonacci_scores: Dict, 
                                 elliott_wave_scores: Dict, timeframe: str) -> float:
        """Calculate weighted composite score from all signal types"""
        
        # Base weights for signal types
        type_weights = {
            'basic': 0.50,
            'fibonacci': 0.25,
            'elliott_wave': 0.25
        }
        
        # Adjust weights based on timeframe
        if timeframe in ['1m', '5m']:
            # For very short timeframes, emphasize basic indicators
            type_weights = {'basic': 0.70, 'fibonacci': 0.15, 'elliott_wave': 0.15}
        elif timeframe in ['1h', 'day']:
            # For longer timeframes, give more weight to advanced analysis
            type_weights = {'basic': 0.40, 'fibonacci': 0.30, 'elliott_wave': 0.30}
        
        composite_score = (
            basic_scores.get('overall_score', 0) * type_weights['basic'] +
            fibonacci_scores.get('overall_score', 0) * type_weights['fibonacci'] +
            elliott_wave_scores.get('overall_score', 0) * type_weights['elliott_wave']
        )
        
        return min(100, max(0, composite_score))

    def _determine_trading_action(self, composite_score: float) -> TradingAction:
        """Determine trading action based on composite score"""
        if composite_score >= self.decision_thresholds['strong_buy']:
            return TradingAction.STRONG_BUY
        elif composite_score >= self.decision_thresholds['buy']:
            return TradingAction.BUY
        elif composite_score >= self.decision_thresholds['hold']:
            return TradingAction.HOLD
        elif composite_score >= self.decision_thresholds['sell']:
            return TradingAction.SELL
        else:
            return TradingAction.STRONG_SELL

    def _generate_reasoning(self, signals: Dict, basic_scores: Dict, 
                          fibonacci_scores: Dict, elliott_wave_scores: Dict,
                          composite_score: float, timeframe: str) -> List[str]:
        """Generate detailed reasoning for the trading decision"""
        reasoning = []
        
        # Overall assessment
        reasoning.append(f"Composite Score: {composite_score:.1f}/100 for {timeframe} timeframe")
        
        # Basic indicators analysis
        if basic_scores.get('overall_score', 0) > 60:
            reasoning.append(f"âœ… Strong basic indicators (Score: {basic_scores['overall_score']:.1f})")
            if basic_scores.get('trend_score', 0) > 70:
                reasoning.append("  â€¢ Trend indicators strongly bullish")
            if basic_scores.get('momentum_score', 0) > 70:
                reasoning.append("  â€¢ Momentum indicators confirm upward movement")
        elif basic_scores.get('overall_score', 0) < 40:
            reasoning.append(f"âŒ Weak basic indicators (Score: {basic_scores['overall_score']:.1f})")
        
        # Fibonacci analysis
        if fibonacci_scores.get('overall_score', 0) > 60:
            reasoning.append(f"âœ… Favorable Fibonacci setup (Score: {fibonacci_scores['overall_score']:.1f})")
            if fibonacci_scores.get('retracement_score', 0) > 80:
                reasoning.append("  â€¢ Price near key Fibonacci retracement level")
        elif fibonacci_scores.get('overall_score', 0) > 0:
            reasoning.append(f"âš ï¸ Moderate Fibonacci signals (Score: {fibonacci_scores['overall_score']:.1f})")
        
        # Elliott Wave analysis
        if elliott_wave_scores.get('overall_score', 0) > 60:
            reasoning.append(f"âœ… Strong Elliott Wave pattern (Score: {elliott_wave_scores['overall_score']:.1f})")
        elif elliott_wave_scores.get('overall_score', 0) > 0:
            reasoning.append(f"âš ï¸ Developing Elliott Wave pattern (Score: {elliott_wave_scores['overall_score']:.1f})")
        
        # Signal details
        entry_signals = signals.get('entry_signals', [])
        exit_signals = signals.get('exit_signals', [])
        
        if entry_signals:
            reasoning.append(f"ðŸ“ˆ Entry signals: {', '.join(entry_signals[:3])}")
        if exit_signals:
            reasoning.append(f"ðŸ“‰ Exit signals: {', '.join(exit_signals[:3])}")
        
        # Risk assessment
        signal_strength = signals.get('signal_strength', 0)
        if signal_strength > 75:
            reasoning.append("ðŸ”¥ High conviction trade setup")
        elif signal_strength < 25:
            reasoning.append("âš ï¸ Low conviction - consider smaller position")
        
        return reasoning

    def _create_timeframe_analysis(self, basic_scores: Dict, fibonacci_scores: Dict, 
                                 elliott_wave_scores: Dict) -> Dict[str, float]:
        """Create analysis breakdown by component"""
        return {
            'basic_indicators': basic_scores.get('overall_score', 0),
            'fibonacci_analysis': fibonacci_scores.get('overall_score', 0),
            'elliott_wave_analysis': elliott_wave_scores.get('overall_score', 0),
            'trend_strength': basic_scores.get('trend_score', 0),
            'momentum_strength': basic_scores.get('momentum_score', 0),
            'volatility_assessment': basic_scores.get('volatility_score', 0)
        }

    def _create_neutral_recommendation(self, reason: str) -> TradingRecommendation:
        """Create a neutral recommendation when analysis fails"""
        return TradingRecommendation(
            action=TradingAction.HOLD,
            confidence=0.0,
            entry_price=None,
            stop_loss=None,
            take_profit=None,
            risk_reward_ratio=None,
            reasoning=[reason],
            timeframe_analysis={}
        )

    def get_multi_timeframe_analysis(self, symbol: str, timeframes: List[str], 
                                   indicators_data: Dict[str, pd.DataFrame]) -> Dict[str, TradingRecommendation]:
        """
        Analyze multiple timeframes and provide comprehensive view
        
        Args:
            symbol: Trading symbol
            timeframes: List of timeframes to analyze
            indicators_data: Dict mapping timeframes to their indicator DataFrames
            
        Returns:
            Dict mapping timeframes to their recommendations
        """
        recommendations = {}
        
        for tf in timeframes:
            if tf in indicators_data and not indicators_data[tf].empty:
                recommendations[tf] = self.analyze_symbol(symbol, tf, indicators_data[tf])
            else:
                recommendations[tf] = self._create_neutral_recommendation(f"No data for {tf}")
        
        return recommendations

    def generate_trading_report(self, symbol: str, timeframe: str, 
                              indicators_df: pd.DataFrame) -> str:
        """Generate a comprehensive trading report"""
        
        recommendation = self.analyze_symbol(symbol, timeframe, indicators_df)
        risk_reward_ratio = (
            f"{recommendation.risk_reward_ratio:.2f}" 
            if recommendation.risk_reward_ratio is not None 
            else "N/A"
        )
        entry_price = (
            f"${recommendation.entry_price:.4f}" 
            if recommendation.entry_price is not None 
            else "N/A"
        )
        stop_loss = (
            f"${recommendation.stop_loss:.4f}" 
            if recommendation.stop_loss is not None 
            else "N/A"
        )
        take_profit = (
            f"${recommendation.take_profit:.4f}" 
            if recommendation.take_profit is not None 
            else "N/A"
        )
        
        report = f"""
## ðŸ“Š Day Trading Analysis Report

**Symbol:** {symbol}  
**Timeframe:** {timeframe}  
**Analysis Time:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Current Price:** ${recommendation.entry_price:.4f} (if available)

### ðŸŽ¯ Trading Recommendation

**Action:** {recommendation.action.value}  
**Confidence:** {recommendation.confidence:.1f}%  
**Risk/Reward Ratio:** {risk_reward_ratio}

### ðŸ’° Risk Management

**Entry Price:** {entry_price} 
**Stop Loss:**  {stop_loss} 
**Take Profit:** {take_profit}

### ðŸ“ˆ Analysis Breakdown

"""
        
        for component, score in recommendation.timeframe_analysis.items():
            report += f"**{component.replace('_', ' ').title()}:** {score:.1f}%\n"
        
        report += "\n### ðŸ” Reasoning\n\n"
        for reason in recommendation.reasoning:
            report += f"â€¢ {reason}\n"
        
        # Add risk warnings
        report += f"""
### âš ï¸ Risk Warnings

â€¢ This analysis is for educational purposes only
â€¢ Past performance does not guarantee future results
â€¢ Always use proper risk management
â€¢ Consider market conditions and news events
â€¢ Maximum recommended risk: 2% of account balance per trade

### ðŸ“‹ Next Steps

"""
        
        if recommendation.action in [TradingAction.STRONG_BUY, TradingAction.BUY]:
            report += """
1. Confirm entry signal with real-time data
2. Set stop loss at recommended level
3. Monitor price action at key levels
4. Consider scaling into position
5. Review risk management rules
"""
        elif recommendation.action in [TradingAction.SELL, TradingAction.STRONG_SELL]:
            report += """
1. Consider closing long positions
2. Look for short opportunities (if applicable)
3. Tighten stop losses on existing trades
4. Wait for better entry opportunities
5. Review market sentiment
"""
        else:
            report += """
1. Wait for clearer signals
2. Monitor key support/resistance levels
3. Watch for breakout patterns
4. Prepare for potential opportunities
5. Review multiple timeframes
"""
        
        return report

# Example usage function
def run_day_trading_analysis(symbol: str, timeframe: str, indicators_df: pd.DataFrame, 
                           account_balance: float = 10000) -> Dict:
    """
    Convenience function to run complete day trading analysis
    
    Args:
        symbol: Trading symbol
        timeframe: Time interval
        indicators_df: DataFrame with calculated indicators
        account_balance: Account balance for position sizing
        
    Returns:
        Dict with recommendation and detailed report
    """
    # Initialize the trading agent
    agent = DayTradingAgent(account_balance=account_balance)
    
    # Get recommendation
    recommendation = agent.analyze_symbol(symbol, timeframe, indicators_df)
    
    # Generate report
    report = agent.generate_trading_report(symbol, timeframe, indicators_df)
    
    return {
        'recommendation': recommendation,
        'report': report,
        'timestamp': datetime.now().isoformat()
    }


##################
#Working fine upper code
#################

class MarketRegime(Enum):
    TRENDING_UP = "trending_up"
    TRENDING_DOWN = "trending_down"
    RANGING = "ranging"
    HIGH_VOLATILITY = "high_volatility"
    LOW_VOLATILITY = "low_volatility"

class SignalQuality(Enum):
    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"
    INVALID = "invalid"

@dataclass
class QualityMetrics:
    signal_strength: float
    confirmation_score: float
    noise_ratio: float
    consistency_score: float
    freshness_score: float
    overall_quality: SignalQuality
    quality_reasons: List[str]

class SignalQualityEngine:
    """Advanced signal quality assessment and filtering system"""
    
    def __init__(self):
        self.quality_thresholds = {
            'excellent': 85,
            'good': 70,
            'fair': 55,
            'poor': 40
        }
        
        # Confirmation requirements for different signal strengths
        self.confirmation_requirements = {
            'strong_signal': 3,  # Need 3+ confirming indicators
            'medium_signal': 2,  # Need 2+ confirming indicators
            'weak_signal': 1     # Need 1+ confirming indicator
        }

    def assess_signal_quality(self, signals: Dict, indicators_df: pd.DataFrame, 
                            timeframe: str) -> QualityMetrics:
        """Comprehensive signal quality assessment"""
        
        # 1. Signal Strength Assessment
        strength_score = self._assess_signal_strength(signals)
        
        # 2. Confirmation Score (multiple indicators agreeing)
        confirmation_score = self._calculate_confirmation_score(signals, indicators_df)
        
        # 3. Noise Ratio (signal clarity vs market noise)
        noise_ratio = self._calculate_noise_ratio(indicators_df, timeframe)
        
        # 4. Consistency Score (signal persistence over time)
        consistency_score = self._assess_signal_consistency(indicators_df)
        
        # 5. Freshness Score (how recent/relevant the signal is)
        freshness_score = self._assess_signal_freshness(indicators_df, timeframe)
        
        # Calculate overall quality score
        overall_score = self._calculate_overall_quality_score(
            strength_score, confirmation_score, noise_ratio, 
            consistency_score, freshness_score
        )
        
        # Determine quality level and reasons
        quality_level, reasons = self._determine_quality_level(
            overall_score, strength_score, confirmation_score, 
            noise_ratio, consistency_score, freshness_score
        )
        
        return QualityMetrics(
            signal_strength=strength_score,
            confirmation_score=confirmation_score,
            noise_ratio=noise_ratio,
            consistency_score=consistency_score,
            freshness_score=freshness_score,
            overall_quality=quality_level,
            quality_reasons=reasons
        )

    def _assess_signal_strength(self, signals: Dict) -> float:
        """Assess the raw strength of signals"""
        entry_signals = signals.get('entry_signals', [])
        exit_signals = signals.get('exit_signals', [])
        signal_strength = signals.get('signal_strength', 0)
        
        # Base score from signal generator
        base_score = signal_strength
        
        # Boost for multiple entry signals
        entry_boost = min(30, len(entry_signals) * 10)
        
        # Penalty for conflicting exit signals
        exit_penalty = min(25, len(exit_signals) * 8)
        
        strength_score = base_score + entry_boost - exit_penalty
        return max(0, min(100, strength_score))

    def _calculate_confirmation_score(self, signals: Dict, indicators_df: pd.DataFrame) -> float:
        """Calculate how well different indicator categories confirm each other"""
        if indicators_df.empty:
            return 0
        
        last_row = indicators_df.iloc[-1]
        confirmations = 0
        total_categories = 0
        
        # Trend Confirmation
        trend_signals = self._get_trend_confirmations(last_row)
        if trend_signals['count'] > 0:
            confirmations += trend_signals['agreement_ratio'] * trend_signals['count']
            total_categories += trend_signals['count']
        
        # Momentum Confirmation
        momentum_signals = self._get_momentum_confirmations(last_row)
        if momentum_signals['count'] > 0:
            confirmations += momentum_signals['agreement_ratio'] * momentum_signals['count']
            total_categories += momentum_signals['count']
        
        # Volume Confirmation
        volume_signals = self._get_volume_confirmations(last_row)
        if volume_signals['count'] > 0:
            confirmations += volume_signals['agreement_ratio'] * volume_signals['count']
            total_categories += volume_signals['count']
        
        # Volatility Confirmation
        volatility_signals = self._get_volatility_confirmations(last_row)
        if volatility_signals['count'] > 0:
            confirmations += volatility_signals['agreement_ratio'] * volatility_signals['count']
            total_categories += volatility_signals['count']
        
        confirmation_score = (confirmations / total_categories * 100) if total_categories > 0 else 0
        return min(100, confirmation_score)

    def _get_trend_confirmations(self, row: pd.Series) -> Dict:
        """Get trend indicator confirmations"""
        trend_indicators = []
        
        # MACD
        macd_signal = row.get('MACDs_12_26_9', 0)
        if pd.notna(macd_signal):
            trend_indicators.append(1 if macd_signal > 0 else -1)
        
        # SMA Crossover
        sma_20 = row.get('SMA_20', 0)
        sma_50 = row.get('SMA_50', 0)
        if pd.notna(sma_20) and pd.notna(sma_50) and sma_20 != 0 and sma_50 != 0:
            trend_indicators.append(1 if sma_20 > sma_50 else -1)
        
        # Supertrend
        supertrend = row.get('SUPERT_7_3.0', 0)
        close_price = row.get('close', 0)
        if pd.notna(supertrend) and pd.notna(close_price) and supertrend != 0:
            trend_indicators.append(1 if close_price > supertrend else -1)
        
        return self._calculate_agreement_ratio(trend_indicators)

    def _get_momentum_confirmations(self, row: pd.Series) -> Dict:
        """Get momentum indicator confirmations"""
        momentum_indicators = []
        
        # RSI
        rsi = row.get('RSI_14', 50)
        if pd.notna(rsi):
            if rsi > 70:
                momentum_indicators.append(-1)  # Overbought
            elif rsi < 30:
                momentum_indicators.append(1)   # Oversold
            elif rsi > 50:
                momentum_indicators.append(0.5) # Bullish bias
            else:
                momentum_indicators.append(-0.5) # Bearish bias
        
        # Stochastic
        stoch_k = row.get('STOCHk_14_3_3', 50)
        if pd.notna(stoch_k):
            if stoch_k > 80:
                momentum_indicators.append(-1)
            elif stoch_k < 20:
                momentum_indicators.append(1)
            elif stoch_k > 50:
                momentum_indicators.append(0.5)
            else:
                momentum_indicators.append(-0.5)
        
        # CCI
        cci = row.get('CCI_14_0.015', 0)
        if pd.notna(cci):
            if cci > 100:
                momentum_indicators.append(-1)
            elif cci < -100:
                momentum_indicators.append(1)
            elif cci > 0:
                momentum_indicators.append(0.5)
            else:
                momentum_indicators.append(-0.5)
        
        return self._calculate_agreement_ratio(momentum_indicators)

    def _get_volume_confirmations(self, row: pd.Series) -> Dict:
        """Get volume indicator confirmations"""
        volume_indicators = []
        
        # OBV trend
        obv = row.get('OBV', 0)
        if pd.notna(obv) and obv != 0:
            # This is simplified - in practice, you'd compare with previous OBV values
            volume_indicators.append(1 if obv > 0 else -1)
        
        # Volume vs Average
        volume = row.get('volume', 0)
        avg_volume = row.get('volume_sma_20', 0)  # Assuming you have this
        if pd.notna(volume) and pd.notna(avg_volume) and avg_volume > 0:
            volume_ratio = volume / avg_volume
            if volume_ratio > 1.5:
                volume_indicators.append(1)  # High volume confirms move
            elif volume_ratio < 0.5:
                volume_indicators.append(-1)  # Low volume weakens signal
        
        return self._calculate_agreement_ratio(volume_indicators)

    def _get_volatility_confirmations(self, row: pd.Series) -> Dict:
        """Get volatility indicator confirmations"""
        volatility_indicators = []
        
        # ATR trend
        atr = row.get('ATR_14', 0)
        atr_sma = row.get('ATR_SMA_20', 0)  # Assuming you have this
        if pd.notna(atr) and pd.notna(atr_sma) and atr_sma > 0:
            volatility_indicators.append(1 if atr > atr_sma else -1)
        
        return self._calculate_agreement_ratio(volatility_indicators)

    def _calculate_agreement_ratio(self, indicators: List[float]) -> Dict:
        """Calculate how much indicators agree with each other"""
        if not indicators:
            return {'count': 0, 'agreement_ratio': 0}
        
        # Convert to numpy array for easier calculation
        indicators = np.array(indicators)
        count = len(indicators)
        
        # Calculate agreement (how close indicators are to each other)
        if count == 1:
            agreement_ratio = 1.0
        else:
            # Calculate standard deviation - lower std means better agreement
            std_dev = np.std(indicators)
            # Convert to agreement ratio (0-1, where 1 is perfect agreement)
            agreement_ratio = max(0, 1 - (std_dev / 2))  # Normalize by max possible std
        
        return {'count': count, 'agreement_ratio': agreement_ratio}

    def _calculate_noise_ratio(self, indicators_df: pd.DataFrame, timeframe: str) -> float:
        """Calculate signal-to-noise ratio"""
        if len(indicators_df) < 10:
            return 50  # Neutral score for insufficient data
        
        # Get recent price data
        recent_data = indicators_df.tail(20)
        close_prices = recent_data['close'].values
        
        # Calculate price volatility (noise)
        price_changes = np.diff(close_prices)
        volatility = np.std(price_changes)
        
        # Calculate trend strength (signal)
        trend_strength = abs(close_prices[-1] - close_prices[0]) / len(close_prices)
        
        # Signal-to-noise ratio
        if volatility == 0:
            noise_ratio = 100  # Perfect signal
        else:
            snr = trend_strength / volatility
            # Convert to 0-100 scale (higher is better)
            noise_ratio = min(100, snr * 20)
        
        # Adjust based on timeframe
        timeframe_multiplier = {
            '1m': 0.7,   # More noise in shorter timeframes
            '5m': 0.8,
            '15m': 0.9,
            '1h': 1.0,
            'day': 1.1   # Less noise in longer timeframes
        }.get(timeframe, 1.0)
        
        return min(100, noise_ratio * timeframe_multiplier)

    def _assess_signal_consistency(self, indicators_df: pd.DataFrame) -> float:
        """Assess how consistent signals have been over recent periods"""
        if len(indicators_df) < 5:
            return 50  # Neutral score for insufficient data
        
        # Look at last 10 periods
        recent_data = indicators_df.tail(10)
        consistency_scores = []
        
        # Check MACD consistency
        macd_signals = recent_data['MACDs_12_26_9'].dropna()
        if len(macd_signals) >= 3:
            # Count sign changes (inconsistency)
            sign_changes = sum(1 for i in range(1, len(macd_signals)) 
                             if np.sign(macd_signals.iloc[i]) != np.sign(macd_signals.iloc[i-1]))
            consistency_scores.append(max(0, 100 - (sign_changes * 25)))
        
        # Check RSI consistency
        rsi_values = recent_data['RSI_14'].dropna()
        if len(rsi_values) >= 3:
            # Check if RSI is trending in one direction
            rsi_trend = np.polyfit(range(len(rsi_values)), rsi_values, 1)[0]
            consistency_scores.append(min(100, abs(rsi_trend) * 10))
        
         # Check price trend consistency
        close_prices = recent_data['close'].dropna()
        if len(close_prices) >= 3:
            price_trend = np.polyfit(range(len(close_prices)), close_prices, 1)[0]
            # Normalize trend strength
            avg_price = np.mean(close_prices)
            trend_strength = abs(price_trend) / avg_price * 100
            consistency_scores.append(min(100, trend_strength * 50))
        
        return np.mean(consistency_scores) if consistency_scores else 50

    def _assess_signal_freshness(self, indicators_df: pd.DataFrame, timeframe: str) -> float:
        """Assess how fresh/recent the signals are"""
        if indicators_df.empty:
            return 0
        
        # Get the timestamp of the last data point
        if 'timestamp' in indicators_df.columns:
            last_timestamp = pd.to_datetime(indicators_df['timestamp'].iloc[-1])
            current_time = datetime.now()
            time_diff = current_time - last_timestamp
            
            # Define freshness thresholds based on timeframe
            freshness_thresholds = {
                '1m': timedelta(minutes=5),
                '5m': timedelta(minutes=15),
                '15m': timedelta(minutes=45),
                '1h': timedelta(hours=3),
                'day': timedelta(days=2)
            }
            
            threshold = freshness_thresholds.get(timeframe, timedelta(hours=1))
            
            if time_diff <= threshold:
                return 100  # Very fresh
            elif time_diff <= threshold * 2:
                return 75   # Moderately fresh
            elif time_diff <= threshold * 4:
                return 50   # Getting stale
            else:
                return 25   # Stale data
        
        return 75  # Default if no timestamp available

    def _calculate_overall_quality_score(self, strength: float, confirmation: float, 
                                       noise: float, consistency: float, freshness: float) -> float:
        """Calculate weighted overall quality score"""
        weights = {
            'strength': 0.25,
            'confirmation': 0.30,
            'noise': 0.20,
            'consistency': 0.15,
            'freshness': 0.10
        }
        
        overall_score = (
            strength * weights['strength'] +
            confirmation * weights['confirmation'] +
            noise * weights['noise'] +
            consistency * weights['consistency'] +
            freshness * weights['freshness']
        )
        
        return min(100, max(0, overall_score))

    def _determine_quality_level(self, overall_score: float, strength: float, 
                               confirmation: float, noise: float, consistency: float, 
                               freshness: float) -> Tuple[SignalQuality, List[str]]:
        """Determine quality level and provide reasons"""
        reasons = []
        
        # Determine overall quality level
        if overall_score >= self.quality_thresholds['excellent']:
            quality = SignalQuality.EXCELLENT
            reasons.append("ðŸŸ¢ Excellent signal quality detected")
        elif overall_score >= self.quality_thresholds['good']:
            quality = SignalQuality.GOOD
            reasons.append("ðŸŸ¡ Good signal quality detected")
        elif overall_score >= self.quality_thresholds['fair']:
            quality = SignalQuality.FAIR
            reasons.append("ðŸŸ  Fair signal quality - proceed with caution")
        elif overall_score >= self.quality_thresholds['poor']:
            quality = SignalQuality.POOR
            reasons.append("ðŸ”´ Poor signal quality - high risk")
        else:
            quality = SignalQuality.INVALID
            reasons.append("âŒ Invalid signal quality - avoid trading")
        
        # Add specific quality insights
        if strength >= 80:
            reasons.append("âœ… Strong signal strength")
        elif strength <= 30:
            reasons.append("âš ï¸ Weak signal strength")
        
        if confirmation >= 75:
            reasons.append("âœ… High indicator confirmation")
        elif confirmation <= 40:
            reasons.append("âš ï¸ Low indicator confirmation")
        
        if noise >= 70:
            reasons.append("âœ… Low market noise")
        elif noise <= 40:
            reasons.append("âš ï¸ High market noise detected")
        
        if consistency >= 70:
            reasons.append("âœ… Consistent signal pattern")
        elif consistency <= 40:
            reasons.append("âš ï¸ Inconsistent signals")
        
        if freshness >= 80:
            reasons.append("âœ… Fresh, recent data")
        elif freshness <= 50:
            reasons.append("âš ï¸ Stale data - signals may be outdated")
        
        return quality, reasons

class MarketRegimeDetector:
    """Detect current market regime to adapt signal interpretation"""
    
    def __init__(self):
        self.regime_thresholds = {
            'trending_strength': 0.6,
            'volatility_high': 1.5,
            'volatility_low': 0.5
        }

    def detect_market_regime(self, indicators_df: pd.DataFrame) -> MarketRegime:
        """Detect the current market regime"""
        if len(indicators_df) < 20:
            return MarketRegime.RANGING  # Default for insufficient data
        
        recent_data = indicators_df.tail(20)
        
        # Calculate trend strength
        trend_strength = self._calculate_trend_strength(recent_data)
        
        # Calculate volatility regime
        volatility_regime = self._calculate_volatility_regime(recent_data)
        
        # Determine regime
        if trend_strength > self.regime_thresholds['trending_strength']:
            # Check if trending up or down
            close_prices = recent_data['close'].values
            if close_prices[-1] > close_prices[0]:
                return MarketRegime.TRENDING_UP
            else:
                return MarketRegime.TRENDING_DOWN
        else:
            # Not trending strongly - check volatility
            if volatility_regime > self.regime_thresholds['volatility_high']:
                return MarketRegime.HIGH_VOLATILITY
            elif volatility_regime < self.regime_thresholds['volatility_low']:
                return MarketRegime.LOW_VOLATILITY
            else:
                return MarketRegime.RANGING

    def _calculate_trend_strength(self, data: pd.DataFrame) -> float:
        """Calculate trend strength using multiple indicators"""
        close_prices = data['close'].values
        
        # Linear regression slope
        x = np.arange(len(close_prices))
        slope, _ = np.polyfit(x, close_prices, 1)
        
        # Normalize slope by average price
        avg_price = np.mean(close_prices)
        normalized_slope = abs(slope) / avg_price
        
        # R-squared for trend consistency
        correlation = np.corrcoef(x, close_prices)[0, 1]
        r_squared = correlation ** 2
        
        # Combine slope strength and consistency
        trend_strength = normalized_slope * r_squared * 100
        
        return min(1.0, trend_strength)

    def _calculate_volatility_regime(self, data: pd.DataFrame) -> float:
        """Calculate current volatility relative to historical average"""
        if 'ATR_14' in data.columns:
            current_atr = data['ATR_14'].iloc[-1]
            avg_atr = data['ATR_14'].mean()
            
            if avg_atr > 0:
                return current_atr / avg_atr
        
        # Fallback: calculate from price changes
        close_prices = data['close'].values
        returns = np.diff(close_prices) / close_prices[:-1]
        current_vol = np.std(returns[-5:])  # Last 5 periods
        avg_vol = np.std(returns)
        
        if avg_vol > 0:
            return current_vol / avg_vol
        
        return 1.0  # Neutral

class SignalFilterEngine:
    """Filter and validate signals based on quality metrics and market regime"""
    
    def __init__(self):
        self.min_quality_thresholds = {
            MarketRegime.TRENDING_UP: SignalQuality.FAIR,
            MarketRegime.TRENDING_DOWN: SignalQuality.FAIR,
            MarketRegime.RANGING: SignalQuality.GOOD,
            MarketRegime.HIGH_VOLATILITY: SignalQuality.GOOD,
            MarketRegime.LOW_VOLATILITY: SignalQuality.FAIR
        }

    def filter_signals(self, signals: Dict, quality_metrics: QualityMetrics, 
                      market_regime: MarketRegime) -> Dict:
        """Filter signals based on quality and market regime"""
        
        # Check minimum quality threshold for current regime
        min_quality = self.min_quality_thresholds.get(market_regime, SignalQuality.GOOD)
        
        filtered_signals = signals.copy()
        
        # Apply quality-based filtering
        if quality_metrics.overall_quality.value < min_quality.value:
            # Reduce signal strength for poor quality
            filtered_signals['signal_strength'] = signals.get('signal_strength', 0) * 0.5
            filtered_signals['quality_warning'] = f"Signal quality ({quality_metrics.overall_quality.value}) below threshold for {market_regime.value} market"
        
        # Apply regime-specific filtering
        filtered_signals = self._apply_regime_filters(filtered_signals, market_regime, quality_metrics)
        
        return filtered_signals

    def _apply_regime_filters(self, signals: Dict, regime: MarketRegime, 
                            quality_metrics: QualityMetrics) -> Dict:
        """Apply market regime-specific signal filters"""
        
        if regime == MarketRegime.RANGING:
            # In ranging markets, prefer mean reversion signals
            signals = self._enhance_mean_reversion_signals(signals)
            
        elif regime in [MarketRegime.TRENDING_UP, MarketRegime.TRENDING_DOWN]:
            # In trending markets, prefer trend-following signals
            signals = self._enhance_trend_following_signals(signals, regime)
            
        elif regime == MarketRegime.HIGH_VOLATILITY:
            # In high volatility, require higher confirmation
            if quality_metrics.confirmation_score < 70:
                signals['signal_strength'] = signals.get('signal_strength', 0) * 0.7
                signals['volatility_warning'] = "High volatility detected - reduced signal strength"
        
        return signals

    def _enhance_mean_reversion_signals(self, signals: Dict) -> Dict:
        """Enhance mean reversion signals for ranging markets"""
        entry_signals = signals.get('entry_signals', [])
        
        # Look for oversold/overbought conditions
        mean_reversion_keywords = ['rsi oversold', 'rsi overbought', 'stochastic', 'cci extreme']
        
        mean_reversion_count = sum(1 for signal in entry_signals 
                                 if any(keyword in signal.lower() for keyword in mean_reversion_keywords))
        
        if mean_reversion_count > 0:
            # Boost signal strength for mean reversion in ranging market
            signals['signal_strength'] = min(100, signals.get('signal_strength', 0) * 1.2)
            signals['regime_boost'] = f"Mean reversion signals enhanced for ranging market"
        
        return signals

    def _enhance_trend_following_signals(self, signals: Dict, regime: MarketRegime) -> Dict:
        """Enhance trend-following signals for trending markets"""
        entry_signals = signals.get('entry_signals', [])
        
        # Look for trend-following signals
        trend_keywords = ['macd', 'sma crossover', 'supertrend', 'breakout']
        
        trend_count = sum(1 for signal in entry_signals 
                         if any(keyword in signal.lower() for keyword in trend_keywords))
        
        if trend_count > 0:
            # Check if signals align with trend direction
            if regime == MarketRegime.TRENDING_UP:
                # Boost bullish signals
                bullish_signals = [s for s in entry_signals if 'bullish' in s.lower() or 'buy' in s.lower()]
                if bullish_signals:
                    signals['signal_strength'] = min(100, signals.get('signal_strength', 0) * 1.3)
                    signals['regime_boost'] = f"Bullish trend-following signals enhanced"
            
            elif regime == MarketRegime.TRENDING_DOWN:
                # Boost bearish signals
                bearish_signals = [s for s in entry_signals if 'bearish' in s.lower() or 'sell' in s.lower()]
                if bearish_signals:
                    signals['signal_strength'] = min(100, signals.get('signal_strength', 0) * 1.3)
                    signals['regime_boost'] = f"Bearish trend-following signals enhanced"
        
        return signals

# Enhanced Advanced Scoring Engine (updated from your original)
class EnhancedAdvancedScoringEngine(AdvancedScoringEngine):
    """Enhanced scoring engine with quality-aware scoring"""
    
    def __init__(self):
        super().__init__()
        self.quality_engine = SignalQualityEngine()
        self.regime_detector = MarketRegimeDetector()
        self.signal_filter = SignalFilterEngine()

    def score_with_quality_assessment(self, signals: Dict, indicators_df: pd.DataFrame, 
                                    timeframe: str) -> Dict:
        """Score signals with comprehensive quality assessment"""
        
        # Assess signal quality
        quality_metrics = self.quality_engine.assess_signal_quality(signals, indicators_df, timeframe)
        
        # Detect market regime
        market_regime = self.regime_detector.detect_market_regime(indicators_df)
        
        # Filter signals based on quality and regime
        filtered_signals = self.signal_filter.filter_signals(signals, quality_metrics, market_regime)
        
        # Get base scores from original methods
        basic_scores = self.score_basic_indicators(filtered_signals)
        
        # Apply quality adjustments to scores
        quality_multiplier = self._get_quality_multiplier(quality_metrics.overall_quality)
        
        # Adjust scores based on quality
        for key in basic_scores:
            if key != 'overall_score':  # Don't double-adjust overall score
                basic_scores[key] = basic_scores[key] * quality_multiplier
        
        # Recalculate overall score with quality adjustment
        weights = self.signal_weights[SignalType.BASIC_INDICATORS]
        basic_scores['overall_score'] = (
            basic_scores['trend_score'] * weights['trend_following'] +
            basic_scores['momentum_score'] * weights['momentum'] +
            basic_scores['volatility_score'] * weights['volatility'] +
            basic_scores['volume_score'] * weights['volume']
        ) * quality_multiplier
        
        # Add quality and regime information to scores
        basic_scores.update({
            'quality_metrics': quality_metrics,
            'market_regime': market_regime,
            'filtered_signals': filtered_signals,
            'quality_multiplier': quality_multiplier
        })
        
        return basic_scores

    def _get_quality_multiplier(self, quality: SignalQuality) -> float:
        """Get quality-based score multiplier"""
        quality_multipliers = {
            SignalQuality.EXCELLENT: 1.2,
            SignalQuality.GOOD: 1.0,
            SignalQuality.FAIR: 0.8,
            SignalQuality.POOR: 0.6,
            SignalQuality.INVALID: 0.3
        }
        return quality_multipliers.get(quality, 1.0)

# Enhanced Day Trading Agent (updated from your original)
class EnhancedDayTradingAgent(DayTradingAgent):
    """Enhanced Day Trading Agent with Signal Quality Assessment"""
    
    def __init__(self, account_balance: float = 10000):
        super().__init__(account_balance)
        # Replace the original scoring engine with enhanced version
        self.scoring_engine = EnhancedAdvancedScoringEngine()
        
        # Enhanced decision thresholds based on quality
        self.quality_adjusted_thresholds = {
            SignalQuality.EXCELLENT: {
                'strong_buy': 70, 'buy': 55, 'hold': 30, 'sell': 15, 'strong_sell': 0
            },
            SignalQuality.GOOD: {
                'strong_buy': 80, 'buy': 65, 'hold': 35, 'sell': 20, 'strong_sell': 0
            },
            SignalQuality.FAIR: {
                'strong_buy': 85, 'buy': 70, 'hold': 40, 'sell': 25, 'strong_sell': 0
            },
            SignalQuality.POOR: {
                'strong_buy': 90, 'buy': 75, 'hold': 45, 'sell': 30, 'strong_sell': 0
            },
            SignalQuality.INVALID: {
                'strong_buy': 95, 'buy': 80, 'hold': 50, 'sell': 35, 'strong_sell': 0
            }
        }

    def analyze_symbol_enhanced(self, symbol: str, timeframe: str, 
                              indicators_df: pd.DataFrame) -> TradingRecommendation:
        """Enhanced analysis with signal quality assessment"""
        try:
            # Get timeframe-specific parameters
            params = get_params_by_timeframe(timeframe)
            
            # Generate signals from your existing signal generator
            signals = self.signal_generator.last_signal(indicators_df, params)
            
            if not signals:
                return self._create_neutral_recommendation("No signals generated")
            
            # Enhanced scoring with quality assessment
            enhanced_scores = self.scoring_engine.score_with_quality_assessment(
                signals, indicators_df, timeframe
            )
            
            # Extract quality metrics and regime information
            quality_metrics = enhanced_scores.get('quality_metrics')
            market_regime = enhanced_scores.get('market_regime')
            filtered_signals = enhanced_scores.get('filtered_signals', signals)
            
            # Get other analysis data
            last_row = indicators_df.iloc[-1]
            fibonacci_data = last_row.get('Fibonacci', {})
            elliott_wave_data = last_row.get('Elliott_Wave', {})
            current_price = last_row.get('close', 0)
            atr_value = last_row.get('ATR_14', None)
            
            # Score Fibonacci and Elliott Wave (using original methods)
            fibonacci_scores = self.scoring_engine.score_fibonacci_signals(fibonacci_data)
            elliott_wave_scores = self.scoring_engine.score_elliott_wave_signals(elliott_wave_data)
            
            # Calculate composite score with quality adjustment
            composite_score = self._calculate_enhanced_composite_score(
                enhanced_scores, fibonacci_scores, elliott_wave_scores, 
                timeframe, quality_metrics
            )
            
            # Generate trading decision with quality-adjusted thresholds
            action = self._determine_quality_adjusted_action(composite_score, quality_metrics.overall_quality)
            
            # Calculate risk management parameters
            stop_loss, take_profit = self.risk_engine.calculate_stop_loss_take_profit(
                current_price, filtered_signals, atr_value
            )
            
            # Generate enhanced reasoning
            reasoning = self._generate_enhanced_reasoning(
                filtered_signals, enhanced_scores, fibonacci_scores, elliott_wave_scores,
                composite_score, timeframe, quality_metrics, market_regime
            )
            
            # Calculate risk-reward ratio
            risk_reward_ratio = None
            if stop_loss and take_profit and current_price:
                risk = abs(current_price - stop_loss)
                reward = abs(take_profit - current_price)
                risk_reward_ratio = reward / risk if risk > 0 else None
            
            # Create enhanced timeframe analysis
            timeframe_analysis = self._create_enhanced_timeframe_analysis(
                enhanced_scores, fibonacci_scores, elliott_wave_scores, quality_metrics
            )
            
            return TradingRecommendation(
                action=action,
                confidence=composite_score,
                entry_price=current_price,
                stop_loss=stop_loss,
                take_profit=take_profit,
                risk_reward_ratio=risk_reward_ratio,
                reasoning=reasoning,
                timeframe_analysis=timeframe_analysis
            )
            
        except Exception as e:
            self.logger.error(f"Error in enhanced analysis for {symbol}: {str(e)}")
            return self._create_neutral_recommendation(f"Enhanced analysis error: {str(e)}")

    def _calculate_enhanced_composite_score(self, enhanced_scores: Dict, fibonacci_scores: Dict,
                                          elliott_wave_scores: Dict, timeframe: str,
                                          quality_metrics: QualityMetrics) -> float:
        """Calculate composite score with quality enhancement"""
        
        # Base composite score calculation
        composite_score = self._calculate_composite_score(
            enhanced_scores, fibonacci_scores, elliott_wave_scores, timeframe
        )
        
        # Apply additional quality-based adjustments
        quality_boost = self._calculate_quality_boost(quality_metrics)
        
        # Apply regime-based adjustments
        regime_adjustment = self._calculate_regime_adjustment(
            enhanced_scores.get('market_regime'), enhanced_scores
        )
        
        final_score = composite_score + quality_boost + regime_adjustment
        
        return min(100, max(0, final_score))

    def _calculate_quality_boost(self, quality_metrics: QualityMetrics) -> float:
        """Calculate quality-based score boost/penalty"""
        base_boost = 0
        
        # Confirmation score boost
        if quality_metrics.confirmation_score >= 80:
            base_boost += 5
        elif quality_metrics.confirmation_score <= 40:
            base_boost -= 5
        
        # Noise ratio boost
        if quality_metrics.noise_ratio >= 70:
            base_boost += 3
        elif quality_metrics.noise_ratio <= 40:
            base_boost -= 3
        
        # Consistency boost
        if quality_metrics.consistency_score >= 75:
            base_boost += 4
        elif quality_metrics.consistency_score <= 35:
            base_boost -= 4
        
        # Freshness boost
        if quality_metrics.freshness_score >= 90:
            base_boost += 2
        elif quality_metrics.freshness_score <= 50:
            base_boost -= 2
        
        return base_boost

    def _calculate_regime_adjustment(self, market_regime: MarketRegime, enhanced_scores: Dict) -> float:
        """Calculate market regime-based adjustments"""
        adjustment = 0
        
        if market_regime == MarketRegime.TRENDING_UP:
            # Boost bullish signals in uptrend
            if enhanced_scores.get('trend_score', 0) > 60:
                adjustment += 3
        elif market_regime == MarketRegime.TRENDING_DOWN:
            # This would boost bearish signals, but since we're looking at bullish bias
            # we might reduce the score or handle differently
            if enhanced_scores.get('trend_score', 0) < 40:
                adjustment += 2  # Bearish trend confirmation
        elif market_regime == MarketRegime.RANGING:
            # In ranging markets, reduce trend-following signals
            if enhanced_scores.get('momentum_score', 0) > enhanced_scores.get('trend_score', 0):
                adjustment += 2  # Favor momentum in ranging markets
        
        return adjustment

    def _determine_quality_adjusted_action(self, composite_score: float, 
                                         quality: SignalQuality) -> TradingAction:
        """Determine trading action with quality-adjusted thresholds"""
        
        thresholds = self.quality_adjusted_thresholds.get(quality, self.decision_thresholds)
        
        if composite_score >= thresholds['strong_buy']:
            return TradingAction.STRONG_BUY
        elif composite_score >= thresholds['buy']:
            return TradingAction.BUY
        elif composite_score >= thresholds['hold']:
            return TradingAction.HOLD
        elif composite_score >= thresholds['sell']:
            return TradingAction.SELL
        else:
            return TradingAction.STRONG_SELL

    def _generate_enhanced_reasoning(self, signals: Dict, enhanced_scores: Dict,
                                   fibonacci_scores: Dict, elliott_wave_scores: Dict,
                                   composite_score: float, timeframe: str,
                                   quality_metrics: QualityMetrics, 
                                   market_regime: MarketRegime) -> List[str]:
        """Generate enhanced reasoning with quality and regime insights"""
        
        reasoning = []
        
        # Overall assessment with quality
        reasoning.append(f"ðŸ“Š Composite Score: {composite_score:.1f}/100 ({quality_metrics.overall_quality.value} quality)")
        reasoning.append(f"ðŸ›ï¸ Market Regime: {market_regime.value.replace('_', ' ').title()}")
        
        # Quality assessment details
        reasoning.append(f"ðŸ” Signal Quality Analysis:")
        reasoning.append(f"  â€¢ Signal Strength: {quality_metrics.signal_strength:.1f}%")
        reasoning.append(f"  â€¢ Confirmation Score: {quality_metrics.confirmation_score:.1f}%")
        reasoning.append(f"  â€¢ Noise Ratio: {quality_metrics.noise_ratio:.1f}%")
        reasoning.append(f"  â€¢ Consistency: {quality_metrics.consistency_score:.1f}%")
        reasoning.append(f"  â€¢ Data Freshness: {quality_metrics.freshness_score:.1f}%")
        
        # Add quality-specific reasons
        reasoning.extend(quality_metrics.quality_reasons)
        
        # Enhanced indicator analysis
        if enhanced_scores.get('overall_score', 0) > 60:
            reasoning.append(f"âœ… Strong technical indicators (Score: {enhanced_scores['overall_score']:.1f})")
            reasoning.append(f"  â€¢ Quality Multiplier Applied: {enhanced_scores.get('quality_multiplier', 1.0):.2f}x")
        
        # Regime-specific insights
        if 'regime_boost' in enhanced_scores.get('filtered_signals', {}):
            reasoning.append(f"ðŸš€ {enhanced_scores['filtered_signals']['regime_boost']}")
        
        if 'quality_warning' in enhanced_scores.get('filtered_signals', {}):
            reasoning.append(f"âš ï¸ {enhanced_scores['filtered_signals']['quality_warning']}")
        
        # Original reasoning (filtered)
        original_reasoning = self._generate_reasoning(
            signals, enhanced_scores, fibonacci_scores, elliott_wave_scores,
            composite_score, timeframe
        )
        
        # Add selected original reasoning (avoid duplicates)
        for reason in original_reasoning:
            if not any(existing in reason for existing in ['Composite Score', 'basic indicators']):
                reasoning.append(reason)
        
        return reasoning

    def _create_enhanced_timeframe_analysis(self, enhanced_scores: Dict, fibonacci_scores: Dict,
                                          elliott_wave_scores: Dict, 
                                          quality_metrics: QualityMetrics) -> Dict[str, float]:
        """Create enhanced timeframe analysis with quality metrics"""
        
        base_analysis = self._create_timeframe_analysis(
            enhanced_scores, fibonacci_scores, elliott_wave_scores
        )
        
        # Add quality metrics to analysis
        base_analysis.update({
            'signal_quality_score': quality_metrics.signal_strength,
            'confirmation_quality': quality_metrics.confirmation_score,
            'noise_level': 100 - quality_metrics.noise_ratio,  # Invert for clarity
            'signal_consistency': quality_metrics.consistency_score,
            'data_freshness': quality_metrics.freshness_score,
            'overall_quality_score': (
                quality_metrics.signal_strength + quality_metrics.confirmation_score +
                quality_metrics.noise_ratio + quality_metrics.consistency_score +
                quality_metrics.freshness_score
            ) / 5
        })
        
        return base_analysis

    def generate_enhanced_trading_report(self, symbol: str, timeframe: str,
                                       indicators_df: pd.DataFrame) -> str:
        """Generate comprehensive trading report with quality assessment"""
        
        recommendation = self.analyze_symbol_enhanced(symbol, timeframe, indicators_df)
        
        # Extract quality information from timeframe analysis
        quality_score = recommendation.timeframe_analysis.get('overall_quality_score', 0)
        confirmation_quality = recommendation.timeframe_analysis.get('confirmation_quality', 0)
        noise_level = recommendation.timeframe_analysis.get('noise_level', 0)
        
        report = f"""
## ðŸ“Š Enhanced Day Trading Analysis Report

**Symbol:** {symbol}  
**Timeframe:** {timeframe}  
**Analysis Time:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Current Price:** ${recommendation.entry_price:.4f}

### ðŸŽ¯ Enhanced Trading Recommendation

**Action:** {recommendation.action.value}  
**Confidence:** {recommendation.confidence:.1f}%  
**Signal Quality:** {quality_score:.1f}%  
**Risk/Reward Ratio:** {recommendation.risk_reward_ratio:.2f if recommendation.risk_reward_ratio else 'N/A'}

### ðŸ” Signal Quality Assessment

**Overall Quality Score:** {quality_score:.1f}%  
**Indicator Confirmation:** {confirmation_quality:.1f}%  
**Market Noise Level:** {noise_level:.1f}%  
**Signal Consistency:** {recommendation.timeframe_analysis.get('signal_consistency', 0):.1f}%  
**Data Freshness:** {recommendation.timeframe_analysis.get('data_freshness', 0):.1f}%

### ðŸ’° Risk Management

**Entry Price:** ${recommendation.entry_price:.4f}  
**Stop Loss:** ${recommendation.stop_loss:.4f if recommendation.stop_loss else 'N/A'}  
**Take Profit:** ${recommendation.take_profit:.4f if recommendation.take_profit else 'N/A'}

### ðŸ“ˆ Enhanced Analysis Breakdown

"""
        
        # Add quality-enhanced component scores
        for component, score in recommendation.timeframe_analysis.items():
            if not component.startswith(('signal_quality', 'confirmation', 'noise', 'data_freshness', 'overall_quality')):
                report += f"**{component.replace('_', ' ').title()}:** {score:.1f}%\n"
        
        report += "\n### ðŸ” Detailed Reasoning\n\n"
        for reason in recommendation.reasoning:
            report += f"â€¢ {reason}\n"
        
        # Enhanced risk warnings based on quality
        report += f"""
### âš ï¸ Enhanced Risk Assessment

"""
        
        if quality_score >= 80:
            report += "ðŸŸ¢ **HIGH QUALITY SIGNALS** - Proceed with standard risk management\n"
        elif quality_score >= 60:
            report += "ðŸŸ¡ **MODERATE QUALITY SIGNALS** - Consider reduced position size\n"
        elif quality_score >= 40:
            report += "ðŸŸ  **FAIR QUALITY SIGNALS** - Use smaller position, tighter stops\n"
        else:
            report += "ðŸ”´ **POOR QUALITY SIGNALS** - Avoid trading or wait for better setup\n"
        
        if confirmation_quality < 50:
            report += "âš ï¸ **LOW CONFIRMATION** - Multiple indicators not aligned\n"
        
        if noise_level > 60:
            report += "âš ï¸ **HIGH MARKET NOISE** - Increased false signal risk\n"
        
        report += f"""
â€¢ Maximum recommended risk: 2% of account balance per trade
â€¢ Consider market conditions and news events
â€¢ This analysis is for educational purposes only
â€¢ Past performance does not guarantee future results

### ðŸ“‹ Quality-Based Action Plan

"""
        
        if recommendation.action in [TradingAction.STRONG_BUY, TradingAction.BUY]:
            if quality_score >= 70:
                report += """
**HIGH CONFIDENCE ENTRY:**
1. âœ… Enter at current market price or on slight pullback
2. âœ… Use standard position sizing (1-2% risk)
3. âœ… Set stop loss at recommended level
4. âœ… Monitor for continuation signals
5. âœ… Consider scaling into position if quality remains high
"""
            else:
                report += """
**CAUTIOUS ENTRY:**
1. âš ï¸ Wait for additional confirmation
2. âš ï¸ Use reduced position size (0.5-1% risk)
3. âš ï¸ Set tighter stop loss
4. âš ï¸ Monitor signal quality improvements
5. âš ï¸ Consider paper trading first
"""
        elif recommendation.action in [TradingAction.SELL, TradingAction.STRONG_SELL]:
            report += """
**EXIT/AVOID STRATEGY:**
1. ðŸš« Close existing long positions
2. ðŸš« Avoid new long entries
3. ðŸš« Consider short opportunities (if applicable)
4. ðŸš« Tighten stop losses on remaining positions
5. ðŸš« Wait for market regime change
"""
        else:
            report += """
**WAIT AND MONITOR:**
1. â³ No action recommended at this time
2. â³ Monitor for signal quality improvement
3. â³ Watch key support/resistance levels
4. â³ Prepare for potential opportunities
5. â³ Review multiple timeframes for confirmation
"""
        
        return report

# Convenience function for enhanced analysis
def run_enhanced_day_trading_analysis(symbol: str, timeframe: str, indicators_df: pd.DataFrame,
                                    account_balance: float = 10000) -> Dict:
    """
    Run enhanced day trading analysis with signal quality assessment
    
    Args:
        symbol: Trading symbol
        timeframe: Time interval
        indicators_df: DataFrame with calculated indicators
        account_balance: Account balance for position sizing
        
    Returns:
        Dict with enhanced recommendation and detailed report
    """
    # Initialize the enhanced trading agent
    agent = EnhancedDayTradingAgent(account_balance=account_balance)
    
    # Get enhanced recommendation
    recommendation = agent.analyze_symbol_enhanced(symbol, timeframe, indicators_df)
    
    # Generate enhanced report
    report = agent.generate_enhanced_trading_report(symbol, timeframe, indicators_df)
    
    # Additional quality metrics for API response
    quality_summary = {
        'overall_quality': recommendation.timeframe_analysis.get('overall_quality_score', 0),
        'signal_strength': recommendation.timeframe_analysis.get('signal_quality_score', 0),
        'confirmation_level': recommendation.timeframe_analysis.get('confirmation_quality', 0),
        'noise_level': recommendation.timeframe_analysis.get('noise_level', 0),
        'consistency': recommendation.timeframe_analysis.get('signal_consistency', 0),
        'freshness': recommendation.timeframe_analysis.get('data_freshness', 0)
    }
    
    return {
        'recommendation': recommendation,
        'report': report,
        'quality_summary': quality_summary,
        'timestamp': datetime.now().isoformat(),
        'version': 'enhanced_v1.0'
    }

# Example usage and testing function
def test_enhanced_signal_quality():
    """Test function to demonstrate enhanced signal quality features"""
    
    # This would be your actual indicators DataFrame
    # For testing, create a sample DataFrame structure
    sample_data = {
        'timestamp': pd.date_range('2024-01-01', periods=50, freq='1H'),
        'close': np.random.randn(50).cumsum() + 100,
        'volume': np.random.randint(1000, 10000, 50),
        'MACDs_12_26_9': np.random.randn(50) * 0.5,
        'RSI_14': np.random.uniform(20, 80, 50),
        'ATR_14': np.random.uniform(0.5, 2.0, 50),
        'STOCHk_14_3_3': np.random.uniform(10, 90, 50),
        'CCI_14_0.015': np.random.randn(50) * 50,
        'OBV': np.random.randn(50).cumsum() * 1000,
        'SMA_20': np.random.randn(50).cumsum() + 99,
        'SMA_50': np.random.randn(50).cumsum() + 98,
        'SUPERT_7_3.0': np.random.randn(50).cumsum() + 97,
        'Fibonacci': [{}] * 50,  # Empty dicts for now
        'Elliott_Wave': [{}] * 50  # Empty dicts for now
    }
    
    test_df = pd.DataFrame(sample_data)
    
    # Run enhanced analysis
    result = run_enhanced_day_trading_analysis('TEST', '1h', test_df)
    
    print("=== Enhanced Signal Quality Test Results ===")
    print(f"Action: {result['recommendation'].action.value}")
    print(f"Confidence: {result['recommendation'].confidence:.1f}%")
    print(f"Overall Quality: {result['quality_summary']['overall_quality']:.1f}%")
    print(f"Signal Strength: {result['quality_summary']['signal_strength']:.1f}%")
    print(f"Confirmation Level: {result['quality_summary']['confirmation_level']:.1f}%")
    print("\nFirst 5 reasoning points:")
    for i, reason in enumerate(result['recommendation'].reasoning[:5]):
        print(f"{i+1}. {reason}")
    
    return result

if __name__ == "__main__":
    # Run test
    test_result = test_enhanced_signal_quality()